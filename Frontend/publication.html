<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta content="width=device-width, initial-scale=1.0" name="viewport">

  <title>Machine Learning and Computational Intelligence Group</title>
  <meta content="" name="description">
  <meta content="" name="keywords">

  <!-- Favicons -->
  <link href="assets/img/favicon.png" rel="icon">
  <link href="assets/img/apple-touch-icon.png" rel="apple-touch-icon">

  <!-- Google Fonts -->
  <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,600,600i,700,700i|Raleway:300,300i,400,400i,500,500i,600,600i,700,700i|Poppins:300,300i,400,400i,500,500i,600,600i,700,700i" rel="stylesheet">

  <!-- Vendor CSS Files -->
  <link href="assets/vendor/animate.css/animate.min.css" rel="stylesheet">
  <link href="assets/vendor/aos/aos.css" rel="stylesheet">
  <link href="assets/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
  <link href="assets/vendor/bootstrap-icons/bootstrap-icons.css" rel="stylesheet">
  <link href="assets/vendor/boxicons/css/boxicons.min.css" rel="stylesheet">
  <link href="assets/vendor/remixicon/remixicon.css" rel="stylesheet">
  <link href="assets/vendor/swiper/swiper-bundle.min.css" rel="stylesheet">

  <!-- Template Main CSS File -->
  <link href="assets/css/style.css" rel="stylesheet">


  <!-- ======= Header ======= -->
  <header id="header" class="fixed-top">
    <div class="container d-flex align-items-center">

      <h1 class="logo me-auto"><a href="index.html"><img src="assets/img/logo.jpg" class="img-fluid" alt="NITC"></a></h1>
    

      <nav id="navbar" class="navbar order-last order-lg-0">
        <ul>
          <li><a href="index.html">Home</a></li>
          <li class="dropdown"><a href="#"><span>People</span> <i class="bi bi-chevron-down"></i></a>
            <ul>
              <li><a href="people_faculty.html">Faculties</a></li>
              <li><a href="people_current.html">Current Students</a></li>
              <li><a href="people_alumni.html">Alumni</a></li>
            </ul>
          </li>
          <li class="dropdown"><a href="#"><span>Projects</span> <i class="bi bi-chevron-down"></i></a>
            <ul>
              <li><a href="projects_ongoing.html">Ongoing Projects</a></li>
              <li><a href="projects_done.html">Completed Projects</a></li>
            </ul>
          </li>
          <li><a href="publication.html">Publications</a></li>
          <li><a  class="active" href="contact.html">Contact</a></li>
        </ul>
        <i class="bi bi-list mobile-nav-toggle"></i>
      </nav>


    </div>
  </header><!-- End Header -->

  <main id="main" data-aos="fade-in">

    <!-- ======= Breadcrumbs ======= -->
    <div class="breadcrumbs">
      <div class="container">
        <h2>Publications</h2>
        <p>As far as he can achieve it, readability is as important for the scientific writer as it is for the novelist.</p>
      </div>
    </div><!-- End Breadcrumbs -->





    <!-- ======= Courses Section ======= -->
    <section id="courses" class="courses">
      <div class="container" data-aos="fade-up">





    <!-- Jay prakesh sir  -->

        <div class="border border-info my-2  d-flex " style="width:25rem">
         
          <img src="./assets/img/JP.jpg" style="width: 10rem; height:10rem" class=" p-2" alt="..."> 
          <div class="d-flex flex-column p-2">
            <p class="card-text fw-bold">Dr Jay Prakesh</p>
            <p class="card-text">National Institute of Technology Calicut</p>
            <p class="card-text" ></p><a class="link-primary fs-7" href="https://scholar.google.com/citations?view_op=list_works&hl=en&hl=en&user=K9zg8jkAAAAJ">Know more</a></p>
          </div>

        </div>



    <table class="table">
      <thead class="table-dark">
        <tr>
          <th scope="col">Title</th>
          <th scope="col">Description</th>
          <th scope="col">Year</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td><a href="https://www.sciencedirect.com/science/article/pii/S0925231216308189" class="link-primary">NSABC: Non-dominated sorting based multi-objective artificial bee colony algorithm and its application in data clustering</a></td>
          <td>This paper presents a non-dominated sorting based multi-objective artificial bee colony algorithm NSABC to solve multi-objective optimization problems. It is an extension of the artificial bee colony algorithm ABC, which is a single objective optimization algorithm, to the multi-objective optimization domain. It uses a novel approach in the employee bee phase to steer the solutions to simultaneously achieve both the orthogonal goals in the multi-objective optimization – convergence and diversity. The onlooker bee phase is similar to the ABC except for the fitness computation to exploit the promising solutions whereas there is no change in the scout bee phase, which is used to get rid of bad solutions and add diversity in the swarm by introducing random solutions. Along with a novel way of exploring new solutions, it uses non-dominated sorting and crowding distance, inspired by the NSGA-II, to maintain the best and diverse solutions in the swarm. It is tested on the 10 two-objective and three-objective unconstrained benchmark problems of varying nature and complexities from the CEC09 suite of test problems and is found better than or commensurable to thirteen state-of-the-art significant multi-objective optimization algorithms as well as other multi-objective variants of the ABC. Further, it is tested on the nine real-life data clustering problems considered from the UCI machine learning repository and proved itself better in comparison to the NSGA-II, MOVGA, and a recent multi-objective variant of the ABC named MOABC. Thus, it is observed that the NSABC is comparatively a simple, light, and powerful algorithm to solve multi-objective problems.</td>
          <td>2016</td>
        </tr>
       
        <tr>
          <td><a href="https://link.springer.com/article/10.1007/s12293-014-0147-5" class="link-primary">An effective multiobjective approach for hard partitional clustering</a></td>
          <td>Clustering is an unsupervised classification method in the field of data mining. Many population based evolutionary and swarm intelligence optimization methods are proposed to optimize clustering solutions globally based on a single selected objective function which lead to produce a single best solution. In this sense, optimized solution is biased towards a single objective, hence it is not equally well to the data set having clusters of different geometrical properties. Thus, clustering having multiple objectives should be naturally optimized through multiobjective optimization methods for capturing different properties of the data set. To achieve this clustering goal, many multiobjective population based optimization methods, e.g., multiobjective genetic algorithm, mutiobjective particle swarm optimization (MOPSO), are proposed to obtain diverse tradeoff solutions in the pareto-front. As single directional diversity mechanism in particle swarm optimization converges prematurely to local optima, this paper presents a two-stage diversity mechanism in MOPSO to improve its exploratory capabilities by incorporating crossover operator of the genetic algorithm. External archive is used to store non-dominated solutions, which is further utilized to find one best solution having highest F-measure value at the end of the run. Two conceptually orthogonal internal measures SSE and connectedness are used to estimate the clustering quality. Results demonstrate effectiveness of the proposed method over its competitors MOPSO, non-dominated sorting genetic algorithm, and multiobjective artificial bee colony on seven real data sets from UCI machine learning repository.</td>
          <td>2015</td>
        </tr>

        <tr>
          <td><a href="https://link.springer.com/article/10.1007/s00500-017-2923-x" class="link-primary">Gravitational search algorithm and K-means for simultaneous feature selection and data clustering: a multi-objective approach</a></td>
          <td>Clustering is an unsupervised classification method used to group the objects of an unlabeled data set. The high dimensional data sets generally comprise of irrelevant and redundant features also along with the relevant features which deteriorate the clustering result. Therefore, feature selection is necessary to select a subset of relevant features as it improves discrimination ability of the original set of features which helps in improving the clustering result. Though many metaheuristics have been suggested to select subset of the relevant features in wrapper framework based on some criteria, most of them are marred by the three key issues. First, they require objects class information a priori which is unknown in unsupervised feature selection. Second, feature subset selection is devised on a single validity measure; hence, it produces a single best solution biased toward the cardinality of the feature subset. Third, they find difficulty in avoiding local optima owing to lack of balancing in exploration and exploitation in the feature search space. To deal with the first issue, we use unsupervised feature selection method where no class information is required. To address the second issue, we follow pareto-based approach to obtain diverse trade-off solutions by optimizing conceptually contradicting validity measures silhouette index (Sil) and feature cardinality (d). For the third issue, we introduce genetic crossover operator to improve diversity in a recent Newtonian law of gravity-based metaheuristic binary gravitational search algorithm (BGSA) in multi-objective optimization scenario; it is named as improved multi-objective BGSA for feature selection (IMBGSAFS). We use ten real-world data sets for comparison of the IMBGSAFS results with three multi-objective methods MBGSA, MOPSO, and NSGA-II in wrapper framework and the Pearson’s linear correlation coefficient (FM-CC) as a multi-objective filter method. We employ four multi-objective quality measures convergence, diversity, coverage and ONVG. The obtained results show superiority of the IMBGSAFS over its competitors. An external clustering validity index F-measure also establish the above finding. As the decision maker picks only a single solution from the set of trade-off solutions, we employee the F-measure to select a final single solution from the external archive. The quality of final solution achieved by IMBGSAFS is superior over competitors in terms of clustering accuracy and/or smaller subset size.</td>
          <td>2019</td>
        </tr>

        <tr>
          <td><a href="https://ieeexplore.ieee.org/abstract/document/7414677" class="link-primary">Particle swarm optimization with k-means for simultaneous feature selection and data clustering</a></td>
          <td>Clustering is an unsupervised classification task of data mining. The high dimensional data sets generally comprise of irrelevant and redundant features also along with the relevant features, which deteriorate the clustering result. Therefore, to improve the clustering result, feature selection is necessary to select a subset of relevant features to improve discrimination ability of the original set of features. In recent years, evolutionary and swarm intelligence methods have been used extensively to obtain a subset of relevant features by incorporating clustering algorithm, such methods are known as wrapper methods. The Binary Particle Swarm Optimization (BPSO) is a recent and popular swarm intelligence optimization method to perform discrete optimization problem such as feature selection. However, BPSO easily sticks into the local optima due to single information sharing mechanism by the global best particle in the swarm. Therefore, in this paper, we modify BPSO to improve information sharing among particles to avoid local optima by introducing genetic crossover among particles (named as BPSO-X) to produce relevant set of features. We employ BPSO-X and K-means simultaneously to perform feature selection and clustering, respectively, where silhouette index evaluate quality of the selected features. Further, F-measure and Rand index are used as external quality measure for clustering. The performance of the proposed algorithm over competitors is measured in terms of length of the selected subset, relevancy of the selected subset of features, clustering accuracy, robustness, and convergence speed on seven real data sets from the UCI machine learning repository. The BPSO-X outperforms its competitors in terms of all the mentioned criteria.</td>
          <td>2015</td>
        </tr>
        
        <tr>
          <td><a href="https://ieeexplore.ieee.org/abstract/document/7033334" class="link-primary">Evolutionary and swarm intelligence methods for partitional hard clustering</a></td>
          <td>Clustering is an unsupervised classification method where objects in the unlabeled data set are classified on the basis of some similarity measure. The conventional partitional clustering algorithms, e.g., K-Means, K-Medoids have several disadvantages such as the final solution is dependent on initial solution, they easily stuck into local optima. The nature inspired population based global search optimization methods offer to be more effective to overcome the deficiencies of the conventional partitional clustering methods as they possess several desired key features like up gradation of the candidate solutions iteratively, decentralization, parallel nature, and self organizing behavior. In this work, we compare the performance of widely applied evolutionary algorithms namely Genetic Algorithm (GA) and Differential Evolution (DE), and swarm intelligence methods namely Particle Swarm Optimization (PSO) and Artificial Bee Colony (ABC) to find the clustering solutions by evaluating the quality of cluster with internal validity criteria, Sum of Square Error (SSE), which is based on compactness of cluster. Extensive results are compared based on three real and one synthetic data sets.</td>
          <td>2014</td>
        </tr>

        <tr>
          <td><a href="https://link.springer.com/chapter/10.1007/978-81-322-1602-5_155" class="link-primary">An effective hybrid method based on de, ga, and k-means for data clustering</a></td>
          <td>Clustering is an unsupervised classification method and plays essential role in applications in diverse fields. The evolutionary methods attracted attention and gained popularity among the data mining researchers for clustering due to their expedient implementation, parallel nature, ability to search global optima, and other advantages over conventional methods. However, conventional clustering methods, e.g., K-means, are computationally efficient and widely used local search methods. Therefore, many researchers paid attention to hybrid algorithms. However, most of the algorithms lag in proper balancing of exploration and exploitation of solutions in the search space. In this work, the authors propose a hybrid method DKGK. It uses DE to diversify candidate solutions in the search space. The obtained solutions are refined by K-means. Further, GA with heuristic crossover operator is applied for fast convergence of solutions and the obtained solutions are further refined by K-means. This is why proposed method is called DKGK. Performance of the proposed method is compared to that of Deferential Evolution (DE), genetic algorithm (GA), a hybrid of DE and K-means (DEKM), and a hybrid of GA and K-Means (GAKM) based on the sum of intra-cluster distances. The results obtained on three real and two synthetic datasets are very encouraging as the proposed method DKGK outperforms all the competing methods.</td>
          <td>2014</td>
        </tr>

        <tr>
          <td><a href="https://link.springer.com/chapter/10.1007/978-81-322-1041-2_44" class="link-primary">Partitional algorithms for hard clustering using evolutionary and swarm intelligence methods: a survey</a></td>
          <td>Evolutionary and swarm intelligence methods attracted attention and gained popularity among the data mining researchers due to their expedient implementation, parallel nature, ability to search global optima and other advantages over conventional techniques. These methods along with their variants and hybrid approaches have emerged as worthwhile class of methods for clustering. Clustering is an unsupervised classification method. The partitional clustering algorithms look for hard clustering; they decompose the dataset into a set of disjoint clusters. This paper describes a brief review of evolutionary and swarm intelligence methods with their variants and hybrid approaches designed for partitional clustering algorithms for hard clustering of datasets.</td>
          <td>2013</td>
        </tr>

        <tr>
          <td><a href="https://link.springer.com/chapter/10.1007/978-981-13-0589-4_52" class="link-primary">Differential evolution with local search algorithms for data clustering: A comparative study</a></td>
          <td>Clustering is an unsupervised data mining task which groups objects in the unlabeled dataset based on some proximity measure. Many nature-inspired population-based optimization algorithms have been employed to solve clustering problems. However, few of them lack in balancing exploration and exploitation in global search space in their original form. Differential Evolution (DE) is a nature-inspired population-based global search optimization method which is suitable to explore the solution in global search space. However, it lacks in exploiting the solution. To overcome this deficiency, few literatures incorporate local search algorithms in DE to achieve a good solution in the search space. In this work, we have performed a comparative study to show effectiveness of local search algorithms, such as chaotic local search, Levy flight, and Golden Section Search with DE to balance exploration and exploitation in the search space for clustering problem. We employ an internal validity measure, Sum of Squared Error (SSE), to evaluate the quality of cluster which is based on the compactness of the cluster. We select F-measure and rand index as external validity measures. Extensive results are compared based on six real datasets from UCI machine learning repository.</td>
          <td>2019</td>
        </tr>

        <tr>
          <td><a href="https://link.springer.com/article/10.1007/s12293-014-0147-5" class="link-primary">Hybrid Gbest-guided Artificial Bee Colony for hard partitional clustering</a></td>
          <td>Clustering is an unsupervised classification method in the field of data mining and plays an essential role in applications in diverse fields. The K-means and K-Medoids are popular examples of conventional partitional clustering methods, which have been prominently applied in various applications. However, they possess several disadvantages, e.g., final solution is dependent on the initial solution, they easily struck into a local optimum solution. The nature-inspired swarm intelligence (SI) methods are global search optimization methods, which offer to be effective to overcome deficiencies of the conventional methods as they possess several desired key features like upgrading the candidate solutions iteratively, decentralization, parallel nature, and a self organizing behavior. The Artificial Bee Colony (ABC) algorithm is one of the recent and well-known SI method, which has been shown effective in various real-world problems. However, it exhibits lack of balance in the exploration and exploitation and shows a poor convergence speed when the number of features (dimensions) increases. Therefore, we make two modifications in it to enhance its exploration and exploitation capabilities to improve quality of the clustering. First, we introduce a gbest-guided search procedure for the fast convergence, which works effectively in large number of features also as it considers all the dimensions simultaneously. Second, in order to avoid being trapped in a local optima and to enhance the information exchange (social learning) between bees for improved search, we incorporate a crossover operator of the genetic algorithm (GA) into it. The proposed strategy is named as Hybrid Gbest-guided Artificial Bee Colony (HGABC) algorithm. We compare clustering results of the HGABC with ABC, variants of the ABC and other recent competitive methods in the swarm and evolutionary intelligence domain on ten real and two synthetic data sets using external quality measures F-measure and Rand-index. The obtained results demonstrate superiority of the proposed method over its competitors in terms of efficiency and effectiveness.</td>
          <td>2017</td>
        </tr>

        <tr>
          <td><a href="https://ieeexplore.ieee.org/abstract/document/9342208" class="link-primary">Performance Analysis of Machine Learning and Deep Learning Models for Text Classification</a></td>
          <td>Text classification is the task of forming semantic groups of text documents by assigning predefined class labels. It has wide range of real-life applications in various domains such as engineering, medical science, life science, social sciences and humanities, marketing, governance. Currently, machine learning and deep learning algorithms became popular and effective methods to address text classification problems with labelled data. In this work, we analyse the performance of different machine learning and deep learning algorithms for text classification. For this purpose, we selected six machine learning algorithms using three different vectorization techniques and five deep learning algorithms for the performance evaluation which is evaluated based on classification accuracy. All experiments are conducted on the 20 newsgroups dataset. Results indicate that Logistic Regression outperforms over other ML algorithms and a Bi-channel Convolution Neural Network model gains exciting results compared to other deep learning models.</td>
          <td>2020</td>
        </tr>

        <tr>
          <td><a href="https://link.springer.com/chapter/10.1007/978-981-15-5243-4_31" class="link-primary">A BERT-Based Question Representation for Improved Question Retrieval in Community Question Answering Systems</a></td>
          <td>Community question answering (CQA) services have become a prominent place for seeking answers from experts and sharing knowledge in any domain. Retrieving semantically related historical questions for a new query is a critical task in CQA to eliminate duplicate questions and to avoid indefinite waiting time to get responses. One major challenge in question retrieval is the lexical gap between the new question and the question in the archive that is already answered. This problem can be eliminated to a great extent by giving proper embedding for questions. Traditional bag-of-words (BOW) representation for text is being replaced by semantic embedding models like word2vec, Glove, and FastText and the newly released Bidirectional Encoder Representations from Transformers (BERT) model. In this paper, we propose a modified BERT embedding using the topic information obtained by LDA on top of questions preprocessed using the RAKE keyword extraction algorithm. We perform question retrieval based on cosine similarity of question vectors and evaluated the accuracy on the Quora question pair dataset. Results show that the proposed question embedding improves the performance of question retrieval compared with competing models.</td>
          <td>2021</td>
        </tr>

      </tbody>
    </table>







    <!-- Pranesh Sir  -->


    <div class="border border-warning my-2 mt-4 d-flex " style="width:25rem">
         
      <img src="./assets/img/PD.jpg" style="width: 10rem; height:11rem" class=" p-2 my-auto" alt="..."> 
      <div class="d-flex flex-column p-2">
        <p class="card-text fw-bold">Pranesh Das</p>
        <p class="card-text">Assistant Professor, Department of CSE, NIT Calicut</p>
        <p class="card-text" ></p><a class="link-primary fs-7" href="https://scholar.google.com/citations?user=suWm38AAAAAJ&hl=en&oi=ao">Know more</a></p>
      </div>

    </div>

    <table class="table">
      <thead class="table-dark">
        <tr>
          <th scope="col">Title</th>
          <th scope="col">Description</th>
          <th scope="col">Year</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td><a href="https://ieeexplore.ieee.org/abstract/document/6558142" class="link-primary">VFT: A virtualization and fault tolerance approach for cloud computing</a></td>
          <td>Fault tolerance in cloud computing is a grand challenge problem now a days. The main fault tolerance issues in cloud computing are detection and recovery. To combat with these problems, many fault tolerance techniques have been designed to reduce the faults. In this paper, we have proposed a Virtualization and Fault Tolerance (VFT) technique to reduce the service time and to increase the system availability. A Cloud Manager (CM) module and a Decision Maker (DM) are used in our scheme to manage the virtualization, load balancing and to handle the faults. In the first step virtualization and load balancing are done and in the second step fault tolerance is achieved by redundancy, checkpointing and fault handler. VFT is mainly designed to provide reactive fault tolerance. In our proposed approach a fault handler is included in the virtualization part. Fault handler blocks the unrecoverable faulty nodes along with their virtual nodes for future requests and removes the temporary software faults from the recoverable faulty nodes and makes them available for the future requests.</td>
          <td>2013</td>
        </tr>
       
        <tr>
          <td><a href="https://ieeexplore.ieee.org/abstract/document/8307256" class="link-primary">A new class topper optimization algorithm with an application to data clustering</a></td>
          <td>In this paper, a new Class Topper Optimization (CTO) algorithm is proposed. The optimization algorithm is inspired from the learning intelligence of students in a class. The algorithm is population based search algorithm. In this approach, solution is converging towards the best solution. This may lead to a global best solution. To verify the performance of the algorithm, a clustering problem is considered. Five standard data sets are considered for real time validation. The analysis shows that the proposed algorithm performs very well compared to various well known existing heuristic or meta-heuristic optimization algorithms.</td>
          <td>2018</td>
        </tr>

        <tr>
          <td><a href="https://www.sciencedirect.com/science/article/abs/pii/S156849461830320X" class="link-primary">A modified Bee Colony Optimization (MBCO) and its hybridization with k-means for an application to data clustering</a></td>
          <td>Among the nature inspired heuristic or meta-heuristic optimization algorithms, Bee Colony Optimization (BCO) algorithms are widely used to solve clustering problem. In this paper, a modified BCO (MBCO) approach is proposed for data clustering. In the proposed MBCO, the forgiveness characteristics of bees and giving a fair chance to both trustworthy and untrustworthy bees are being taken care of. A probability based selection (Pbselection) approach is introduced in the proposed MBCO for assigning unallocated data points in every iteration. The result shows that, the proposed method gives faster convergence as compared to the existing well known algorithms. In order to improve the performance of MBCO further and to obtain global optimal and diverse solution, the proposed MBCO is hybridized with k-means algorithm. In average, the hybridized MKCLUST and KMCLUST give same or better result than the proposed MBCO. To validate the proposed algorithms, seven standard data sets are considered. From classification error percentages calculation, it is observed that the proposed algorithms perform better compared to some existing algorithms. The simulation results infer that the proposed algorithms can be efficiently used for data clustering.</td>
          <td>2018</td>
        </tr>

        <tr>
          <td><a href="https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.300.7058&rep=rep1&type=pdf" class="link-primary">A randomized searching algorithm and its performance analysis with binary search and linear search algorithms</a></td>
          <td>Design and Analysis of Algorithm is one of the most important areas of Computer Science and Engineering. Searching and Sorting Algorithms play a key rule here. Research conducted over the past fifteen years has amply demonstrated the advantages of algorithms that make random choices in the course of their execution. We have various Searching Algorithms available. In this paper we have proposed a Randomized Searching Algorithm and then performance analysis is done between the proposed Algorithm and the existing Binary Search and Linear Search Algorithms. The performance of the Proposed Algorithm lies between Binary Search and Linear Search.</td>
          <td>2013</td>
        </tr>
        
        <tr>
          <td><a href="https://link.springer.com/article/10.1007/s42979-020-00434-2" class="link-primary">A working prototype using DS18B20 temperature sensor and Arduino for health monitoring</a></td>
          <td>Due to the successful emergence of internet of things, sensor-based real-time health monitoring is getting popularized. A usable health-monitoring system is required for prolonged monitoring of the patient with reduced cost. This paper describes a working prototype system for real-time health-monitoring system using DS18B20 temperature sensor, Arduino Nano with micro-controller ATmega328 where Zigbee module is used for wireless communication. In this prototype sensor data gets acquired and analyzed to give proper feedback to the patient with or without mobility support at indoor. The sensor vitals are collected and sent to the computing device using shielded cable and ZigBee, i.e., through wired and wireless communication, respectively. Analysis of patient vitals based on medical definitions gives patient’s real-time health condition so that if condition is not normal, then timely preventive measures can be taken to avoid further complication. Per user data can be saved in the system database for further reference.</td>
          <td>2020</td>
        </tr>

        <tr>
          <td><a href="https://link.springer.com/article/10.1007/s11277-020-08054-y" class="link-primary">Design and implementation of routing algorithm to enhance network lifetime in wban</a></td>
          <td>Today’s era is the era of smart and remote applications exploiting advancement in sensors, cloud, Internet of things etc. Major application is in healthcare monitoring and support using wireless body area network (WBAN) in which sensor nodes sense vital physiological parameters and send to server through sink i.e. smart phone nowadays for seamless monitoring. The most significant issue in such applications is energy efficiency which leads to enhanced network life time that ensures uninterrupted seamless services. From source to sink data transmission may occur considering three different scenarios: source to sink single hop direct data transmission irrespective of in-between node distance, source to sink multi hop data transmission in which transmission range of source node is fixed at a threshold to find next forwarder node and transmission range of source node is incremented by affixed value until data gets transmitted to sink. In this work WBAN having different network configurations based on fixed or random positions of nodes have been simulated. Different scenarios with fixed and varying number of nodes are framed and simulated using MATLAB 2020a for performance evaluation of proposed algorithm in terms of energy consumption, network lifetime, path loss etc. due to data transmission from source to sink. Experimental results show that incremental approach is better than direct one in terms of energy consumption, path loss and network lifetime. While selecting transmission range of a source node, it is considered to keep Specific Absorption Rate (SAR) lower to reduce impact on human tissue.</td>
          <td>2020</td>
        </tr>

        <tr>
          <td><a href="http://ethesis.nitrkl.ac.in/4993/" class="link-primary">Virtualization and fault tolerance in cloud computing</a></td>
          <td>Fault tolerance in cloud computing is a grand challenge problem now a days. The main fault tolerance issues in cloud computing are detection and recovery. To combat with these problems, many fault tolerance techniques have been designed to reduce the faults. In this research work,a Virtualization and Fault Tolerance (VFT) technique is used to reduce the service time and to increase the system availability. A Cloud Manager (CM) module and a Decision Maker (DM) are used in this scheme to manage the virtualization, load balancing and to handle the faults. In the first step virtualization and load balancing are done and in the second step fault tolerance is achieved by redundancy, checkpointing and fault handler.The main load balancing issues in cloud computing is load calculation and load distribution. To solve these issues, many load balancing techniques have been designed to distribute tasks properly. In this work, a Load Balancing Technique for Virtualization and Fault Tolerance in Cloud Computing (LBVFT) is applied to assign the tasks to the virtual nodes.LBVFT is mainly designed to assign tasks to the virtual nodes depending on the success rates (SR) and the previous load history. In our load assigning technique assignment is done by the load balancer (LB) of cloud manager (CM) module in the basis of higher success rate and lower load of the available nodes.A Randomized Searching Algorithm is designed to select a virtual node.Performance of the Randomized Searching Algorithm lies between Binary Search and Linear Search Algorithms. VFT is mainly designed to provide reactive as well as proactive fault tolerance. In this approach a fault handler is included in the virtualization part. Fault handler blocks the unrecoverable faulty nodes along with their virtual nodes for future requests and removes the temporary software faults from the recoverable faulty nodes and makes them available for the future requests.</td>
          <td>2013</td>
        </tr>

        <tr>
          <td><a href="https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.403.8701&rep=rep1&type=pdf" class="link-primary">LBVFT: A Load Balancing Technique for Virtualization and Fault Tolerance in Cloud Computing</a></td>
          <td>Load balancing in cloud computing is a grand challenge problem now a days. The main load balancing issues in cloud computing is load calculation and load distribution. To solve these issues, many load balancing techniques have been designed to distribute tasks properly. In this paper, we have proposed a Load Balancing Technique for Virtualization and Fault Tolerance in Cloud Computing (LBVFT) to assign the tasks to the virtual nodes. A Cloud Manager (CM) module and a Decision Maker (DM) are used in the proposed scheme to manage the virtualization, load balancing and to handle the faults. LBVFT is mainly designed to assign tasks to the virtual nodes depending on the success rates (SR) and the previous load history. In the load assigning technique assignment is done by the load balancer (LB) of cloud manager (CM) module in the basis of higher success rate and lower load of the available nodes.</td>
          <td>2013</td>
        </tr>

        <tr>
          <td><a href="https://ieeexplore.ieee.org/abstract/document/8423917/" class="link-primary">PSO, BCO and K-means based hybridized optimization algorithms for data clustering</a></td>
          <td>Among the nature inspired heuristic or meta-heuristic optimization algorithms Bee Colony Optimization (BCO) and Particle Swarm Optimization(PSO) algorithms are widely used to solve clustering problems. In this paper, two hybridized optimization algorithms PS-BCO-K and K-PS-BCO are proposed based on PSO, BCO and K-means for data clustering. To validate the proposed algorithms, five standard data sets are considered. The result shows that, the proposed methods give better quality solution as compared to some existing well known heuristic or meta-heuristic optimization algorithms. The simulation results infer that the proposed algorithms can be efficiently used for real time data clustering problem.</td>
          <td>2017</td>
        </tr>

<!-- 
        <tr>
          <td><a href="https://ieeexplore.ieee.org/abstract/document/9342208" class="link-primary">A multi-objective approach for inter-cluster and intra-cluster distance analysis</a></td>
          <td>Text classification is the task of forming semantic groups of text documents by assigning predefined class labels. It has wide range of real-life applications in various domains such as engineering, medical science, life science, social sciences and humanities, marketing, governance. Currently, machine learning and deep learning algorithms became popular and effective methods to address text classification problems with labelled data. In this work, we analyse the performance of different machine learning and deep learning algorithms for text classification. For this purpose, we selected six machine learning algorithms using three different vectorization techniques and five deep learning algorithms for the performance evaluation which is evaluated based on classification accuracy. All experiments are conducted on the 20 newsgroups dataset. Results indicate that Logistic Regression outperforms over other ML algorithms and a Bi-channel Convolution Neural Network model gains exciting results compared to other deep learning models.</td>
          <td>2021</td>
        </tr> -->

        <tr>
          <td><a href="https://ieeexplore.ieee.org/abstract/document/8487933/" class="link-primary">A Multi-objective Modified Particle Swarm Optimization (MMPSO) technique with an application to data clustering</a></td>
          <td>Among the nature inspired heuristic or metaheuristic optimization algorithms Particle Swarm Optimization(PSO) algorithms are widely used to solve clustering problem. In this paper, a modified multi-objective PSO (MMPSO) algorithm is proposed for data clustering. In the proposed MMPSO, the intra-cluster distance and inter-cluster distance are considered as the objective functions. In-order to improve the convergence rate of the MMPSO, a Cloning concept is introduced. To validate the proposed algorithms, five standard data sets are considered. The result shows that, the proposed method gives better quality solution as compared to some existing well known algorithms. The simulation results infer that the proposed algorithms can be efficiently used for data clustering.</td>
          <td>2017</td>
        </tr>

      </tbody>
    </table>









      <!-- Raju Hazari sir -->

    
    <div class="border border-success my-2 mt-4 d-flex " style="width:25rem">
         
      <img src="./assets/img/RH.jpg" style="width: 10rem; height:11rem" class=" p-2 my-auto" alt="..."> 
      <div class="d-flex flex-column p-2">
        <p class="card-text fw-bold">Raju Hazari</p>
        <p class="card-text">Assistant Professor, Department of CSE, National Institute of Technology, Calicut</p>
        <p class="card-text" ></p><a class="link-primary fs-7" href="https://scholar.google.com/citations?user=rcogsCMAAAAJ&hl=en&oi=ao">Know more</a></p>
      </div>

    </div>

    <table class="table">
      <thead class="table-dark">
        <tr>
          <th scope="col">Title</th>
          <th scope="col">Description</th>
          <th scope="col">Year</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td><a href="https://content.wolfram.com/uploads/sites/13/2018/12/23-2-4.pdf" class="link-primary">Number Conservation Property of Elementary Cellular Automata under Asynchronous Update</a></td>
          <td>This paper studies the number conservation property of elementary cellular automata (ECAs) under asynchronous update. In asynchronous update, any number of cells can be updated in each time step. It is, however, shown in the beginning of the study that no elementary cellular automaton (ECA), in general, can be claimed as number conserving under asynchronous update. Our goal was to search for some ECAs that conserve the number of 1s and 0s of any initial configuration for at least one update pattern. As a result of this search, we get a set of 64 ECAs. Each of these ECAs can sometimes show the number conservation property under asynchronous update. The probability of showing the number conservation property of these 64 ECAs may be small, but it is nonzero. However, in the update of these number-conserving ECAs, only passive transitions may be observed. We proceed by searching some ECAs (from the set of 64 ECAs) that show the number conservation property even with active transitions against some initial configurations. Here we identify 49 ECAs that obey this criterion. We finally extract nine ECAs from these 49 ECAs that can show the number conservation property with only active transitions against each of the possible initial configurations except for two homogeneous configurations: one with cell state 0 and the other with cell state 1. We conclude our study after presenting an asynchronous update scheme for these number-conserving ECAs.</td>
          <td>2014</td>
        </tr>
       
        <tr>
          <td><a href="http://search.ebscohost.com/login.aspx?direct=true&profile=ehost&scope=site&authtype=crawler&jrnl=15575969&AN=127449183&h=rJidg5cRaR3L2%2F4IGXYCM3GajovHcjnkVTQFNqazE0Q7K3UjoTNABEkra%2Bw5NoAMlWeqZqGsNx3r1Ps9NcJRdw%3D%3D&crl=c" class="link-primary">Number Conservation Property of Binary Cellular Automata Under α-Asynchronous Update</a></td>
          <td>This paper studies the number conservation behavior of binary asynchronous cellular automata (ACAs). We consider here a-asynchronous update scheme. It is, however, shown in the beginning of the study that no binary CA (except identity rule), in general, can be claimed as number conserving under asynchronous update. We then introduce the idea of probabilistic number conservation of ACAs. We find a set of binary ACAs which are probabilistic number conserving ACAs. We observe that these ACAs are not dependent on any specific value of a. Further, some additional ACAs have been found which have a tendency to conserve the expected number of 1s of the seeds having density 0.5.</td>
          <td>2018</td>
        </tr>

        <tr>
          <td><a href="https://arxiv.org/abs/1604.06600" class="link-primary">On number conservation of non-uniform cellular automata</a></td>
          <td>This paper studies the number conservation property of 1-dimensional non-uniform cellular automata (CAs). In a non-uniform cellular automaton (CA), different cells may follow different rules. The present work considers that the cells follow Wolfram's CAs rules. A characterization tool, named Reachability tree is used to discover the number conservation property of non-uniform CAs. Then a decision algorithm is reported to conclude whether a given non-uniform CA with  cells is number conserving or not. Finally, a synthesis scheme is developed to get an -cell number conserving non-uniform CA.</td>
          <td>2016</td>
        </tr>

        <tr>
          <td><a href="https://ieeexplore.ieee.org/abstract/document/6526574/" class="link-primary">Design of Hardware for Deterministic Nagel-Schreckenberg Traffic Model</a></td>
          <td>The Nagel-Schreckenberg (NS) model is a primitive traffic model that can excellently simulate the road traffic behavior. To our knowledge, no target has been taken till date to design hardware for the NS model. In this scenario, this paper reports a hardware design for a variant of NS model, called deterministic NS model. The proposed hardware drastically reduces simulation time, which would help the traffic engineers and scientists to efficiently experiment with NS model for the study of road traffic behavior.</td>
          <td>2012</td>
        </tr>
        
        <tr>
          <td><a href="http://search.ebscohost.com/login.aspx?direct=true&profile=ehost&scope=site&authtype=crawler&jrnl=15575969&AN=127770036&h=XfogJzDi9wOS%2BN%2B%2BU6xtsNn99ZxRG6IlvBmVtgA1OcS0odSbcynZ5GQETOyNby4MVmQ5NvbELVwIRxqv56g1ow%3D%3D&crl=c" class="link-primary">ECA 184 Can Implement Any Logic Circuits.</a></td>
          <td>Clustering is an unsupervised classification method where objects in the unlabeled data set are classified on the basis of some similarity measure. The conventional partitional clustering algorithms, e.g., K-Means, K-Medoids have several disadvantages such as the final solution is dependent on initial solution, they easily stuck into local optima. The nature inspired population based global search optimization methods offer to be more effective to overcome the deficiencies of the conventional partitional clustering methods as they possess several desired key features like up gradation of the candidate solutions iteratively, decentralization, parallel nature, and self organizing behavior. In this work, we compare the performance of widely applied evolutionary algorithms namely Genetic Algorithm (GA) and Differential Evolution (DE), and swarm intelligence methods namely Particle Swarm Optimization (PSO) and Artificial Bee Colony (ABC) to find the clustering solutions by evaluating the quality of cluster with internal validity criteria, Sum of Square Error (SSE), which is based on compactness of cluster. Extensive results are compared based on three real and one synthetic data sets.</td>
          <td>2018</td>
        </tr>
<!-- 
        <tr>
          <td><a href="https://link.springer.com/chapter/10.1007/978-81-322-1602-5_155" class="link-primary">On Number Conservation Property of ECA under α-Asynchronous Update</a></td>
          <td>
            This paper establishes that ECA 184 can implement any logic circuits. We first show that the basic logic gates, such as AND, OR, NOT, NAND, XOR etc. can be realized by evolving ECA 184. Since any logic circuit can be implemented by utilizing basic logic gates, ECA 184 can implement all logic circuit. Finally, some other widely used combinational logic circuits, such as ADDER can also be implemented by evolving ECA 184</td>
          <td>2014</td>
        </tr> -->

        <tr>
          <td><a href="https://scholar.google.com/scholar?cluster=13508148615181883870&hl=en&oi=scholarr" class="link-primary">Number Conservation In Cellular Automata</a></td>
          <td>This thesis studies the number conservation behavior of cellular automata (CAs). A cellular automaton (CA) is said to be number-conserving (NCCA) if the sum of the states of its cells remains invariant during evolution of the CA. Classically, CAs are uniform where all the cells of a CA follow same next state function (rule) to evolve. In this research, we first explore the number conservation issue in the domain of non-classical CAs. In particular, we explore asynchronous CAs (ACAs) and non-uniform CAs. For the study of ACAs, we use two types of update scheme–(i) using update pattern and (ii) using α-asynchronous update. While we explore the number conservation property under asynchronous update, it is, however, revealed that no binary ACA (except the identity rules), in general, can be claimed as number conserving.</td>
          <td>2019</td>
        </tr>

        <tr>
          <td><a href="https://www.worldscientific.com/doi/abs/10.1142/S0129183118500407" class="link-primary">Rule 136 and its equivalents are liberal, but become conservative in their conjugal life</a></td>
          <td>Rule 136 and its equivalents, rules 192, 238 and 252, are not number conserving rules. Out of these four, 136 and 192 are number nonincreasing rules, whereas 238 and 252 are number nondecreasing rules. However, when a non-uniform cellular automation (CA) is formed with rules 136 and 252, or 192 and 238 in alternate positions, the CA becomes conservative. This paper studies these non-uniform CAs. It is further shown that, except rules 136, 192, 238 and 252, no other number nonincreasing and nondecreasing rules can participate in a non-uniform CA to form a conservative system.</td>
          <td>2018</td>
        </tr>

      </tbody>
    </table>




      </div>
    </section><!-- End Courses Section -->

  </main><!-- End #main -->







  <!-- ======= Footer ======= -->
  <footer id="footer">

    <div class="container d-md-flex py-4">

      <div class="me-md-auto text-center text-md-start">
        Department of Computer Science and Engineering <br />
        National Institute of Technology Calicut
      </div>

      <div class="social-links text-center text-md-right pt-3 pt-md-0">
        <a href="#" class="twitter"><i class="bx bxl-twitter"></i></a>
        <a href="#" class="facebook"><i class="bx bxl-facebook"></i></a>
        <a href="#" class="instagram"><i class="bx bxl-instagram"></i></a>
        <a href="#" class="google-plus"><i class="bx bxl-skype"></i></a>
        <a href="#" class="linkedin"><i class="bx bxl-linkedin"></i></a>
      </div>
    </div>
  </footer><!-- End Footer -->

  <div id="preloader"></div>
  <a href="#" class="back-to-top d-flex align-items-center justify-content-center"><i class="bi bi-arrow-up-short"></i></a>

  <!-- Vendor JS Files -->
  <script src="assets/vendor/aos/aos.js"></script>
  <script src="assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
  <script src="assets/vendor/php-email-form/validate.js"></script>
  <script src="assets/vendor/purecounter/purecounter.js"></script>
  <script src="assets/vendor/swiper/swiper-bundle.min.js"></script>

  <!-- Template Main JS File -->
  <script src="assets/js/main.js"></script>

</body>

</html>